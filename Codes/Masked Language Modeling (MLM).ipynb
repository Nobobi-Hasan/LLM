{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bdc8411-7ad0-4329-a833-c6301e45bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bb5f47f-ebb9-4b26-9558-552e2307ed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d89f604-786d-460a-aee2-00d43dd3a0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-cased\"\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "766618e5-fadd-43be-9555-a1cc323e639c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[MASK]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the mask token\n",
    "mask = tokenizer.mask_token\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd1f58d-e7f9-423d-94a3-8825ff914911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'want', 'to', '[MASK]', 'pizza', 'for', 'tonight', '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = f\"I want to {mask} pizza for tonight.\"\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59c88a2e-1d8d-4f07-935a-2144d9613f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_inputs size =  torch.Size([1, 10])\n",
      "MaskedLMOutput(loss=None, logits=tensor([[[ -7.3723,  -7.2489,  -7.4421,  ...,  -6.3119,  -5.9369,  -6.4257],\n",
      "         [ -7.9311,  -8.2282,  -8.0326,  ...,  -6.7387,  -6.4877,  -6.9525],\n",
      "         [-12.0500, -11.7972, -12.5776,  ...,  -8.4518,  -6.7310,  -8.2586],\n",
      "         ...,\n",
      "         [-10.2204, -10.4315,  -9.9993,  ...,  -7.9570,  -6.7194,  -9.3618],\n",
      "         [-12.4471, -12.5367, -12.5614,  ...,  -9.9086,  -9.4219, -11.1769],\n",
      "         [-14.3657, -14.5227, -15.0017,  ..., -11.9715, -11.6569, -13.4498]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "encoded_inputs = tokenizer(sentence, return_tensors='pt')\n",
    "print('encoded_inputs size = ', encoded_inputs.input_ids.size())\n",
    "output = model(**encoded_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81d76140-b0b9-4c5b-9299-be32396237ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 28996])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.size()\n",
    "# output shape = (1*encoded_inputs.input_ids.size()*vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3de55eb9-513f-45ec-b7c9-a274ed30f3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 28996)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detaching the logits from the model output and converting to numpy array\n",
    "logits = output.logits.detach().numpy()[0]\n",
    "# logits gives probabilities of each token in the vocab for each position.\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2877ca8e-d949-45c0-ae6c-e0c211e4bc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.index(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7b9d2c6-3816-4049-9eec-2f13b54caa01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.7146316, -6.3791103, -6.1184897, ..., -5.651311 , -3.657279 ,\n",
       "       -4.9947295], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_logits = logits[tokens.index(mask) + 1] # +1 because there is a start token in the encoded_inputs\n",
    "mask_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "431c5ad4-d1dd-44d3-8777-dd8accd98205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28996,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44c33ab1-3dd2-453c-9028-54f2734d4475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.9159913e-10, 4.0785011e-10, 5.2928223e-10, ..., 8.4446233e-10,\n",
       "       6.2026513e-09, 1.6282841e-09], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_score = softmax(mask_logits)\n",
    "confidence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e538b8c-a2bb-4169-9ee0-afec2c3794ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2572899"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(confidence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19f1f9a6-bd4d-490b-961b-87d61002ccc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1138"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(confidence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "530633ff-ff1f-4366-92f2-ad3541ff37b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2572899"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_score[1138]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5f6b9c0-1168-4d10-974c-8d95a86417a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(1138)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bad8507d-09a3-4d79-980e-03a3da89ed5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1138, 1243, 3940, 1294, 1546], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(confidence_score)[::-1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "438ca57e-8e5d-4d7f-87df-e920d9d5ceb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to have pizza for tonight. : Confidence score: 0.2572899\n",
      "I want to get pizza for tonight. : Confidence score: 0.17849591\n",
      "I want to eat pizza for tonight. : Confidence score: 0.1555557\n",
      "I want to make pizza for tonight. : Confidence score: 0.11422386\n",
      "I want to order pizza for tonight. : Confidence score: 0.09823085\n"
     ]
    }
   ],
   "source": [
    "# sentence was: \"I want to {mask} pizza for tonight.\"\n",
    "for i in np.argsort(confidence_score)[::-1][:5]:\n",
    "    pred_token = tokenizer.decode(i)\n",
    "    score = confidence_score[i]\n",
    "    print(sentence.replace(mask, pred_token), ': Confidence score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc0799-4726-4121-9381-6834d91e4318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
